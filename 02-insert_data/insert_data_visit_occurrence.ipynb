{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4878318a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57947/3760276594.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import time\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "771a17fb-344c-4f5e-a4e9-b6f0de12af5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/20 18:04:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/10/20 18:04:01 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "23/10/20 18:04:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "       .master(\"local[*]\") \\\n",
    "       .appName(\"test\")\\\n",
    "       .config(\"spark.driver.extraClassPath\", \"/dados10t/datalake/raw/omop/docker_imagens/postgresql-42.6.0.jar\")\\\n",
    "       .config(\"spark.driver.memory\", \"80g\")\\\n",
    "       .config(\"spark.executor.memory\", \"50g\")\\\n",
    "       .config(\"spark.dirver.maxResultSize\", \"50g\")\\\n",
    "       .config('spark.local.dir', '/dados10t/datalake/raw/checkpoint_dir')\\\n",
    "       .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setCheckpointDir('/dados10t/datalake/raw/checkpoint_dir')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34529252",
   "metadata": {},
   "source": [
    "#### reading table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f912b70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet('/dados10t/datalake/standard/omop/tabelas_omop_cmd_5.4_v1/tb_visit_occurrence_data.parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a17ac7d9-957a-4b33-9c2d-a95c95c8e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df\\\n",
    ".withColumn('visit_occurrence_id', F.col('visit_occurrence_id').cast(IntegerType()))\\\n",
    ".withColumn('person_id', F.col('person_id').cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b236ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ca80f3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- visit_occurrence_id: long (nullable = true)\n",
      " |-- visit_concept_id: integer (nullable = true)\n",
      " |-- visit_start_date: date (nullable = true)\n",
      " |-- visit_end_date: date (nullable = true)\n",
      " |-- care_site_id: integer (nullable = true)\n",
      " |-- visit_type_concept_id: integer (nullable = true)\n",
      " |-- person_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f2d699e-006d-4b08-88f0-4576ad12d889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cnae = spark.read.parquet(\"/dados10t/datalake/standard/omop/tabelas_omop_cmd_5.4_v1/tb_care_site.parquet\")\n",
    "table_p_cnae = df.join(cnae, 'care_site_id' ,'left')\n",
    "table_p_cnae = table_p_cnae.withColumn('valid_cnae',\n",
    "                                       F.when(F.col('care_site_source_value').isNull() & F.col('care_site_id').isNotNull(), 0)\n",
    "                                       .otherwise(1))\n",
    "table_p_cnae = table_p_cnae.withColumn('care_site_id',\n",
    "                                       F.when(F.col('valid_cnae') == 0, None)\\\n",
    "                                       .otherwise(F.col('care_site_id'))\n",
    "                                      )\n",
    "table_p_cnae = table_p_cnae.select(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9192c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    \"url\": \"jdbc:postgresql://157.86.211.201:5432/postgres\",\n",
    "    \"dbtable\": \"omop54_v2.visit_occurrence\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"omop2023\",\n",
    "    \"postgreSQLConf\": \"constraint.mode=noconstraints\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eb27562",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .options(**options) \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f3c88e3-78a1-4c5c-812b-623b6545ba3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "print(\"finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
